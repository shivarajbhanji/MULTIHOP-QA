{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07eac8b-7147-4769-8d38-1a94c7a587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-vector-stores-qdrant llama-index-readers-file llama-index-embeddings-fastembed llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bbd46-8b8b-4adf-96d4-d12ca1067709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149f2c6-7b24-4306-ab1a-8e8c43f2aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivarajbhanji/udemy_nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from llama_index.core import VectorStoreIndex, Settings, SimpleDirectoryReader\n",
    "# from llama_index.core import Settings\n",
    "\n",
    "\n",
    "# from llama_index.core.query_pipeline import QueryPipeline\n",
    "# from llama_index.retrievers.bm25 import BM25Retriever\n",
    "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "import torch\n",
    "# from llama_index.llms.llama_cpp import LlamaCPP\n",
    "# from llama_index.core.query_pipeline import QueryPipeline, FnComponent \n",
    "# from llama_index.core.query_pipeline import Link  # Add this import\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import qdrant_client\n",
    "from qdrant_client import QdrantClient\n",
    "from together import Together\n",
    "import json\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48107f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e7d66-4b24-40db-9c74-847d32a64489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(json_path):\n",
    "    \"\"\"Read corpus.json and convert to LlamaIndex documents\"\"\"\n",
    "    from llama_index.core import Document\n",
    "    import json\n",
    "    \n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    for item in data:\n",
    "        documents.append(Document(\n",
    "            text=item[\"body\"],\n",
    "            metadata={\n",
    "                \"title\": item[\"title\"],\n",
    "                \"author\": item[\"author\"],\n",
    "                \"source\": item[\"source\"],\n",
    "                \"published_at\": item[\"published_at\"],\n",
    "                \"category\":item[\"category\"],\n",
    "                \"url\":item[\"url\"]\n",
    "            }\n",
    "        ))\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0631b-ad76-4453-8e09-01f065b53dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not in use\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "#     device=\"mps\")\n",
    "    \n",
    "# node_parser = SentenceSplitter(\n",
    "#         chunk_size=256,\n",
    "#         chunk_overlap=25,\n",
    "#     )\n",
    "    \n",
    "#     # Create processed nodes\n",
    "# documents = load_corpus(\"corpus.json\")\n",
    "# nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    \n",
    "# vector_index = VectorStoreIndex(nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f43f48-0682-4ce2-81cf-16933063babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents and create nodes\n",
    "documents = load_corpus(\"corpus.json\") \n",
    "node_parser = SentenceSplitter(chunk_size=256, chunk_overlap=25)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0204082-7b66-43d5-ad10-3d8fcf491742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e5541-3a5b-42e0-819e-0663fb17fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to Qdrant Cloud\n",
    "quadrant_client = qdrant_client.QdrantClient(\n",
    "    url=os.getenv(\"QUADRANT_DB_URL\"),  # Quadrant DB URL\n",
    "    api_key=os.getenv(\"QUADRANT_API_KEY\")\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=quadrant_client,\n",
    "    collection_name=\"bge-large-256-embedds\",\n",
    "    embedding_dim=1024  # Dimension for bge-large-en-v1.5 embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0c563-472d-4735-bed4-4fb15a2adfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bacba0-b4c9-48ae-b7b8-7a2aaf9623bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # testing if context is retreived given a query\n",
    "# print(quadrant_client.get_collections())  \n",
    "# #print(f\"Total nodes to index: {len(nodes)}\")\n",
    "# query= \"Does the article from Polygon discussing the Barbie film describe Mattel's portrayal in the same light as how The Independent - Life and Style article describes Mattel's handling of the Wilma Mankiller Barbie doll?\"\n",
    "\n",
    "# query_embedding = embed_model.get_text_embedding(query)\n",
    "    \n",
    "#     # Search in Qdrant\n",
    "# search_result = quadrant_client.search(\n",
    "#         collection_name=\"multihop-embedds\",\n",
    "#         query_vector=query_embedding,\n",
    "#         limit=10\n",
    "#     )\n",
    "# search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb04c9-f03a-40cd-8e7c-2574df32f057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from io import StringIO\n",
    "def search_similar(query):\n",
    "    query_embedding = embed_model.get_text_embedding(query)\n",
    "    \n",
    "    # Search in Qdrant\n",
    "    search_result = quadrant_client.search(\n",
    "        collection_name=\"bge-large-256-embedds\",\n",
    "        query_vector=query_embedding,\n",
    "        limit=10\n",
    "    )\n",
    "    data_list = []\n",
    "    \n",
    "    for point in search_result:\n",
    "        data_list.append({\n",
    "        \"text\": f\"[Excerpt from document]\\ntitle: {point.payload.get(\"title\")}\\npublished_at: {point.payload.get(\"published_at\")}\\nsource: {point.payload.get(\"source\")}\\nExcerpt:\\n-----\\n{json.load(StringIO(point.payload.get(\"_node_content\")))[\"text\"]}\",\n",
    "        \"score\": point.score\n",
    "        })\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e44ee-53fe-4d11-83d5-c5fec8cbbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret_texts=[data[\"text\"] for data in data_list]\n",
    "# ret_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fa75a-90ad-415e-86fe-97d18d2d603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_docs(json_path):\n",
    "    \"\"\"Read corpus.json and convert to LlamaIndex documents\"\"\"\n",
    "    from llama_index.core import Document\n",
    "    import json\n",
    "    \n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    for item in data:\n",
    "        documents.append({\n",
    "                \"query\": item[\"query\"],\n",
    "                \"question_type\": item[\"question_type\"],\n",
    "                \"retrieval_list\": search_similar(item[\"query\"]),\n",
    "                \"gold_list\": item[\"evidence_list\"],\n",
    "            }\n",
    "        )\n",
    "    return documents\n",
    "similar_docs = get_relevant_docs(\"MultiHopRAG.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb260bf1-971f-4257-83a3-4a6287b8ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(\"multihop_qa_256_final_output.json\", \"w\")\n",
    "json.dump(similar_docs, out_file, indent = 6)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ed60c-bd6d-4a77-8ec6-084100addcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #query = \"What are 'skip-level' meetings?\"\n",
    "# #query=\"Does 'The New York Times' article attribute the success of the Buffalo Bills' defense to the contributions of Jordan Poyer, while the 'Sporting News' article suggests that the Baltimore Ravens' defense needs to improve before their game against the Cincinnati Bengals?\"\n",
    "# #query= \"Who is the individual associated with the cryptocurrency industry facing a criminal trial on fraud and conspiracy charges, as reported by both The Verge and TechCrunch, and is accused by prosecutors of committing fraud for personal gain?\"\n",
    "# #query=\"Who is the figure associated with generative AI technology whose departure from OpenAI was considered shocking according to Fortune, and is also the subject of a prevailing theory suggesting a lack of full truthfulness with the board as reported by TechCrunch?\"\n",
    "# #query=\"Do the TechCrunch article on software companies and the Hacker News article on The Epoch Times both report an increase in revenue related to payment and subscription models, respectively?\"\n",
    "# #query=\"Has the portrayal of Google's market practices in reports by The Age before October 22, 2023, remained consistent with the depiction in The Verge's coverage of the Epic v. Google case, and with TechCrunch's report on the class action antitrust suit filed against Google?\"\n",
    "# #query=\"Does the TechCrunch article suggest that Amazon's large language model (LLM) is not trained on kids' responses, while The Age article raises concerns about TikTok's pixel collecting data without consent?\"\n",
    "# #test_query=\"Do 'The Verge' and 'Engadget' articles both suggest that 'Consumers' have guides or opportunities to make better purchasing decisions, while 'TechCrunch' discusses 'Consumers' desire for a new model in a different sector?\"\n",
    "# test_query= \"Does the TalkSport article suggest that Manchester United's defensive performance in the Champions League group stages is worse than in previous years, as indicated by a new record for goals conceded, while The Guardian article implies that Manchester United's overall performance under pressure in the Champions League, especially in Istanbul, has been consistently poor?\"\n",
    "# test_query= \"Does the article from Polygon discussing the Barbie film describe Mattel's portrayal in the same light as how The Independent - Life and Style article describes Mattel's handling of the Wilma Mankiller Barbie doll?\"\n",
    "# test_query=similar_docs[0][\"query\"]\n",
    "# ret_texts=[doc[\"text\"] for doc in similar_docs[0][\"retrieval_list\"]]\n",
    "# prefix = \"Below is a question followed by some context from different sources. Please answer the question based on the context. The answer to the question is a word or entity. If the provided information is insufficient to answer the question, respond 'Insufficient Information'. Answer directly without explanation.\"\n",
    "# response = llmClient.chat.completions.create(\n",
    "#     model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "#     messages=[\n",
    "#       {\"role\": \"system\", \"content\": \"You are a helpful chatbot.\"},\n",
    "#       {\"role\": \"user\", \"content\": f\"{prefix}:{test_query}:{\"\\n\".join(ret_texts)}\"},\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983f9c16-fd79-406d-b242-277b9e8b4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kindo_api_methods import KindoAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d0fe8-c1ee-487b-bec8-6f807746d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "kindo_api = KindoAPI(api_key=os.getenv(\"KINDO_API_KEY\"))\n",
    "#response = kindo_api.call_kindo_api(model=\"groq/llama3-70b-8192\", messages=[{\"role\": \"user\", \"content\": f\"{prefix}:{test_query}:{\"\\n\".join(ret_texts)}\"}], max_tokens=200).json()['choices'][0]['message']['content']\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbae51-ec7b-4031-b8f7-181efc3a139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"multihop_qa_256_output.json\") as f:\n",
    "    data = json.load(f)  \n",
    "    similar_docs = []\n",
    "    for item in data:\n",
    "        similar_docs.append({\n",
    "            \"query\":item[\"query\"],\n",
    "            \"question_type\":item[\"question_type\"],\n",
    "            \"retrieval_list\":item[\"retrieval_list\"],\n",
    "            \"gold_list\":item[\"gold_list\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c31e44-518e-44a2-8d84-55773e3cc0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "prefix = \"Below is a question followed by some context from different sources. Please answer the question based on the context. The answer to the question is a word or entity. If the provided information is insufficient to answer the question, respond 'Insufficient Information'. Answer directly without explanation.\"\n",
    "for i in range(len(similar_docs)):\n",
    "    query=similar_docs[i][\"query\"]\n",
    "    ret_texts=[doc[\"text\"] for doc in similar_docs[i][\"retrieval_list\"]]\n",
    "    response = kindo_api.call_kindo_api(model=\"groq/llama3-70b-8192\", messages=[{\"role\": \"user\", \"content\": f\"{prefix}:{query}:{\"\\n\".join(ret_texts)}\"}], max_tokens=200)['choices'][0]['message']['content']\n",
    "    similar_docs[i][\"answer\"]=response\n",
    "    if(i%10==0):\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505d755d-d42b-4049-992d-2410c69b1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_data(json_path):\n",
    "    with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "    documents = []\n",
    "    for item in data:\n",
    "        documents.append({\n",
    "                \"query\": item[\"query\"],\n",
    "                \"question_type\": item[\"question_type\"],\n",
    "                \"retrieval_list\": item[\"retrieval_list\"],\n",
    "                \"gold_list\": item[\"gold_list\"],\n",
    "            }\n",
    "        )\n",
    "    return documents\n",
    "gpt_4o_docs=get_gpt_data(\"multihop_qa_256_final_output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8fc0c-9e76-4970-85f4-c3c2eeb02fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://llm.kindo.ai/v1/chat/completions, details: {'error': 'Invalid JSON response', 'content': '{\"error\":{\"message\":\"CHAT_INSUFFICIENT_CREDITS: You have exceeded your current quota of daily API calls. Please contact support to upgrade your plan: https://kindo.ai/contact\",\"type\":\"None\",\"param\":\"None\",\"code\":\"403\"}}'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m ret_texts\u001b[38;5;241m=\u001b[39m[doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m gpt_4o_docs[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_list\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     10\u001b[0m total_tokens\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ret_texts)\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m     11\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mkindo_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_kindo_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mazure/gpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquery\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_texts\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\n\u001b[0;32m---> 15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m gpt_4o_docs[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(i,response)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import re\n",
    "llm_model=\"azure/gpt-4o\"\n",
    "prefix = \"Below is a question followed by some context from different sources. Please answer the question based on the context. The answer to the question is a word or entity. If the provided information is insufficient to answer the question, respond 'Insufficient Information'. Answer directly without explanation.\"\n",
    "total_tokens=0\n",
    "for i in range(len(gpt_4o_docs)):\n",
    "    query = gpt_4o_docs[i][\"query\"]\n",
    "    ret_texts=[doc[\"text\"] for doc in gpt_4o_docs[i][\"retrieval_list\"]]\n",
    "    total_tokens+=len(\"\".join(ret_texts).split())\n",
    "    response = kindo_api.call_kindo_api(\n",
    "                model=\"azure/gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"{prefix}:{query}:\\n{'\\n'.join(ret_texts)}\"}],\n",
    "                max_tokens=200\n",
    "            ).json()['choices'][0]['message']['content']\n",
    "    gpt_4o_docs[i][\"answer\"] = response\n",
    "    print(i,response)\n",
    "    if i%5==0:\n",
    "        print(total_tokens)\n",
    "        total_tokens=0\n",
    "        print(\"sleep for 60secs\")\n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b053c5d0-17cb-4fec-b577-d9ea71e1fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(\"multihop_qa_256_gpt4o_output.json\", \"w\")\n",
    "json.dump(gpt_4o_docs, out_file, indent = 6)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56128a-b434-408d-83e0-8ffc15968194",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question Type: inference_query\n",
    " Precision: 0.87\n",
    " Recall: 0.87\n",
    " F1 Score: 0.87\n",
    "\n",
    "Question Type: comparison_query\n",
    " Precision: 0.13\n",
    " Recall: 0.13\n",
    " F1 Score: 0.13\n",
    "\n",
    "Question Type: null_query\n",
    " Precision: 0.21\n",
    " Recall: 0.21\n",
    " F1 Score: 0.21\n",
    "\n",
    "Question Type: temporal_query\n",
    " Precision: 0.25\n",
    " Recall: 0.25\n",
    " F1 Score: 0.25\n",
    "\n",
    "Overall Metrics:\n",
    " Precision: 0.40\n",
    " Recall: 0.40\n",
    " F1 Score: 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f638a5-b998-4503-b525-c9125500ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate file: multihop_qa_256_output.json(512 due to mistake)\n",
    "For file: multihop_qa_256_output.json(512 due to mistake)\n",
    "Hits@10: 0.8457\n",
    "Hits@4: 0.6568\n",
    "MAP@10: 0.2149\n",
    "MRR@10: 0.4438\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4a870-19b3-42af-93b3-35e541aaf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "For file: multihop_qa_256_final_output.json\n",
    "Hits@10: 0.7397\n",
    "Hits@4: 0.5463\n",
    "MAP@10: 0.1787\n",
    "MRR@10: 0.3937\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ba6f2-6296-4ba7-8f1c-5a4c147657e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embeddings of 512 chunk size\n",
    "Question Type: inference_query\n",
    " Precision: 0.87\n",
    " Recall: 0.87\n",
    " F1 Score: 0.87\n",
    " accuracy: 0.80\n",
    "\n",
    "Question Type: comparison_query\n",
    " Precision: 0.13\n",
    " Recall: 0.13\n",
    " F1 Score: 0.13\n",
    " accuracy: 0.36\n",
    "\n",
    "Question Type: null_query\n",
    " Precision: 0.21\n",
    " Recall: 0.21\n",
    " F1 Score: 0.21\n",
    " accuracy: 0.39\n",
    "\n",
    "Question Type: temporal_query\n",
    " Precision: 0.25\n",
    " Recall: 0.25\n",
    " F1 Score: 0.25\n",
    " accuracy: 0.40\n",
    "\n",
    "Overall Metrics:\n",
    " Precision: 0.40\n",
    " Recall: 0.40\n",
    " F1 Score: 0.40\n",
    " Accuracy: 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f278d6-4d58-43b6-a64b-4f4b0c8881d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question Type: inference_query\n",
    " Precision: 0.91\n",
    " Recall: 0.91\n",
    " F1 Score: 0.91\n",
    " accuracy: 0.85\n",
    "\n",
    "Question Type: comparison_query\n",
    " Precision: 0.12\n",
    " Recall: 0.12\n",
    " F1 Score: 0.12\n",
    " accuracy: 0.36\n",
    "\n",
    "Question Type: null_query\n",
    " Precision: 0.33\n",
    " Recall: 0.33\n",
    " F1 Score: 0.33\n",
    " accuracy: 0.43\n",
    "\n",
    "Question Type: temporal_query\n",
    " Precision: 0.30\n",
    " Recall: 0.30\n",
    " F1 Score: 0.30\n",
    " accuracy: 0.42\n",
    "\n",
    "Overall Metrics:\n",
    " Precision: 0.44\n",
    " Recall: 0.44\n",
    " F1 Score: 0.44\n",
    " Accuracy: 0.47"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (udemy_nlp)",
   "language": "python",
   "name": "udemy_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
